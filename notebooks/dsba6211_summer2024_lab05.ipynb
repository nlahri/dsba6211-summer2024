{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlahri/dsba6211-summer2024/blob/main/notebooks/dsba6211_summer2024_lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install umap-learn\n",
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "wmEa9p1883It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "ZOl_YTQF7H0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu8vMwrT69TJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# import csv\n",
        "data_url = \"https://raw.githubusercontent.com/sultanawar321/reviews_text_classification/main/data/reviews.csv\"\n",
        "\n",
        "df = pd.read_csv(data_url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's keep only the raw text\n",
        "docs = [_ for _ in df['ReviewBody']]\n",
        "\n",
        "len(docs)"
      ],
      "metadata": {
        "id": "FXOTGhcE7OnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "nnnvgf1m7bPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib bar chart of length of each string in docs list\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist([len(doc) for doc in docs], bins=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AqwNyY_kIxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scikit-learn pipeline"
      ],
      "metadata": {
        "id": "BxlbDZf1r-_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import umap\n",
        "\n",
        "# Create a TF-IDF pipeline\n",
        "tfidf_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "    (\"svd\", TruncatedSVD(n_components=50, random_state=42)),\n",
        "    (\"umap\", umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42))\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the text data\n",
        "tfidf_pipeline.fit(docs)\n",
        "\n",
        "# Transform the text data into the UMAP representation\n",
        "umap_representations = tfidf_pipeline.transform(docs)"
      ],
      "metadata": {
        "id": "o5Y7Mzmv8XdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "XqlAFNRbr9Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the TF-IDF vectorizer from the pipeline\n",
        "tfidf_vectorizer = tfidf_pipeline.named_steps[\"tfidf\"]\n",
        "\n",
        "# Get the vocabulary from the TF-IDF vectorizer\n",
        "vocabulary = tfidf_vectorizer.vocabulary_\n",
        "\n",
        "doc_idx = 0\n",
        "print(docs[doc_idx])"
      ],
      "metadata": {
        "id": "BuRSooZDAFnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the TF-IDF weights\n",
        "tfidf_weights = tfidf_vectorizer.transform(docs)\n",
        "\n",
        "# Get for sample document\n",
        "print(tfidf_weights[0])"
      ],
      "metadata": {
        "id": "HJJyAQhXlZAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the words with the highest frequency in the document\n",
        "top_words = np.argsort(tfidf_weights[0].toarray())[0][-1:]\n",
        "\n",
        "# Print the top words\n",
        "for word_idx in top_words:\n",
        "    word = list(vocabulary.keys())[list(vocabulary.values()).index(word_idx)]\n",
        "    print(word)"
      ],
      "metadata": {
        "id": "9eHBg19GAUlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert sparse array to dense array for easier calculation\n",
        "dense_weights = tfidf_weights.toarray()\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Explore the top 20 words with the highest average TF-IDF weights\n",
        "avg_weights = np.mean(dense_weights, axis=1)\n",
        "top_idx = np.argsort(-avg_weights)[:20]\n",
        "print(\"Top 20 words with highest average TF-IDF weights:\")\n",
        "for idx in top_idx:\n",
        "    print(f\"{feature_names[idx]}: {avg_weights[idx]:.4f}\")\n",
        "\n",
        "# Explore the distribution of TF-IDF weights for all documents\n",
        "plt.hist(avg_weights, bins=50)\n",
        "plt.xlabel(\"Average TF-IDF weight\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of average TF-IDF weights\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b4zTRm7PtFL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most common words across all documents\n",
        "common_words = np.argsort(-np.sum(dense_weights, axis=0))[:10]\n",
        "print(\"Most common words across all documents:\")\n",
        "for idx in common_words:\n",
        "    print(f\"{feature_names[idx]}: {np.sum(dense_weights[:, idx]):.4f}\")"
      ],
      "metadata": {
        "id": "_sz-i2hxxl_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See [this demo](https://pair-code.github.io/understanding-umap/) for more intuition on UMAP."
      ],
      "metadata": {
        "id": "fTeev4wtAxCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Plot the UMAP representation of the documents with altair\n",
        "plt.scatter(umap_representations[:, 0], umap_representations[:, 1], alpha=0.5)\n",
        "plt.xlabel(\"UMAP Dimension 1\")\n",
        "plt.ylabel(\"UMAP Dimension 2\")\n",
        "plt.title(\"UMAP Representation of Documents\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NF1FMrsO7fxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now cluster the UMAP representation using DBSCAN.\n",
        "\n",
        "For more details on DBSCAN, watch [this](https://youtu.be/RDZUdRSDOok?feature=shared) StatQuest video."
      ],
      "metadata": {
        "id": "VPID0-xBnwiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Run DBSCAN clustering on the UMAP representation\n",
        "dbscan = DBSCAN(eps=0.1, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(umap_representations)\n",
        "\n",
        "df = pd.DataFrame(np.column_stack((umap_representations, dbscan_labels, docs)), columns=[\"x\", \"y\", \"dbscan_cats\",\"text\"])\n",
        "\n",
        "alt.Chart(df).mark_circle().encode(\n",
        "    x=\"x:Q\",\n",
        "    y=\"y:Q\",\n",
        "    color = \"dbscan_cats:N\",\n",
        "    tooltip=[\"x\", \"y\", \"dbscan_cats\", \"text\"]\n",
        ").interactive()"
      ],
      "metadata": {
        "id": "OzgphcWh9axP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view examples\n",
        "from ipywidgets import interact\n",
        "\n",
        "def get_examples(index, cat):\n",
        "    return [_ for _ in df[df[\"dbscan_cats\"] == cat].text][index]\n",
        "\n",
        "interact(get_examples, index=(0, 18), cat=\"77\")"
      ],
      "metadata": {
        "id": "b9g2coDjPolm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling\n",
        "\n",
        "This is just one implementation of Topic Modeling (Non-negative Matrix Factorization, a close cousin of the most popular LDA topic modeling technique).\n",
        "\n",
        "It's important to remember that topic modeling is a task, not a model itself. There are a variety of algorithms, most of which have been replaced recently by word embedding based approaches (e.g., see [BERTopic](https://maartengr.github.io/BERTopic/index.html)).\n",
        "\n",
        "Very important points to remember about topic modeling:\n",
        "\n",
        "1. Running the model is the start, not the end. It requires human interpretation after running the model. Do not forgot this (#1 mistake by new data scientists)!\n",
        "\n",
        "2. Validation is critical; don't just accept the model. It's unsupervised so you need to use knowledge to check the model.\n",
        "\n",
        "3. Evaluation is hard and not as clear as supervised ML. There are metrics (e.g., Perplexity) but these are more theoretical and in practice hard to justify.\n",
        "\n",
        "4. Topic modeling is all about exploration: \"learning what you don't know\". Very rarely are topic models into production."
      ],
      "metadata": {
        "id": "YA5SXdHUC5ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "# Run NMF topic modeling\n",
        "nmf = NMF(n_components=20, random_state=42)\n",
        "nmf_topics = nmf.fit_transform(tfidf_pipeline.named_steps[\"tfidf\"].fit_transform(docs))"
      ],
      "metadata": {
        "id": "NFKQt7e6-JYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_top_words(model, feature_names, n_top_words, title):\n",
        "    fig, axes = plt.subplots(4, 5, figsize=(30, 15), sharex=True)\n",
        "    axes = axes.flatten()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_features_ind = topic.argsort()[-n_top_words:]\n",
        "        top_features = feature_names[top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7)\n",
        "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
        "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
        "        for i in \"top right left\".split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "        fig.suptitle(title, fontsize=40)\n",
        "\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "    plt.show()\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "plot_top_words(\n",
        "    nmf, tfidf_feature_names, 10, \"Topics in NMF model\"\n",
        ")"
      ],
      "metadata": {
        "id": "325L99laCdHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Questions\n",
        "\n",
        "## Questions 1\n",
        "\n",
        "Write a Python function that uses the `similarity_matrix` and the index of a document (e.g., document 0) and returns the k-most similar documents.\n",
        "- Include a 2nd optional parameter to set k, which by default should be 10."
      ],
      "metadata": {
        "id": "q-T797Ks2w6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the document similarity using cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity(dense_weights)\n",
        "print(\"Document similarity matrix:\")\n",
        "print(similarity_matrix)"
      ],
      "metadata": {
        "id": "HZuTa61xu1w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the 10 most similar documents to this document\n",
        "docs[0]"
      ],
      "metadata": {
        "id": "D3L0hT8fvaLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Answer this:\n",
        "\n",
        "- Write a Python function/code to find what are the 10 most similar documents to document `0` (provide an list of the indices). You may use ChatGPT but you **must** provide your prompt (e.g., provide a [shared link](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq)). If you don't, you'll lose points.\n",
        "\n",
        "`!<--- ADD CODE SNIPPET BELOW AND THEN ANSWER HERE -->!`\n",
        "\n",
        "- Read through the 10 most similar documents; what is a recurring theme in the documents? what is the most similar topic in the NMF topic modeling?\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`\n",
        "\n",
        "- Critique this search; what are ways in accuracy, speed, and reduced memory you could improve this (feel free to use outside references)?\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`"
      ],
      "metadata": {
        "id": "F6LW1e2L944d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write code here"
      ],
      "metadata": {
        "id": "zV8AJ-DQ4ElS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "\n",
        "For this question, use this code to visualize in UMAP that color codes documents based on:\n",
        "\n",
        "- Query: Document 0 from Q1 (blue)\n",
        "- Results: Top 100 documents most similar to Document 0 (red)\n",
        "- Other: All other documents (in light grey)\n",
        "\n",
        "1. Replace the `df.loc[!<-- PUT ANSWER FROM Q1 HERE, CHANGE FOR k=100 --> !, \"text_type\"]`\n",
        "2. Run the code below and analyze the plot (e.g., zoom in and find some of the examples)\n",
        "\n",
        "### Answer this:\n",
        "\n",
        "- Explain why the top 100 most similar documents to the query are **not** the nearest neighbors on the plot.\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`"
      ],
      "metadata": {
        "id": "aKvP-I-q5HxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate altair code to plot umap representations\n",
        "import altair as alt\n",
        "\n",
        "df = pd.DataFrame(np.column_stack((umap_representations, docs)), columns=[\"x\", \"y\", \"text\"])\n",
        "# add column for document type; add in your function from Q1 to #######\n",
        "# df[\"text_type\"] = \"Other\"\n",
        "# df.loc[#######, \"text_type\"] = \"Results\"\n",
        "# df.loc[0, \"text_type\"] = \"Query\"\n",
        "\n",
        "alt.Chart(df).mark_circle().encode(\n",
        "    x=\"x:Q\",\n",
        "    y=\"y:Q\",\n",
        "    # color = alt.Color('text_type',\n",
        "    #                   scale=alt.Scale(domain=['Other', 'Query', 'Results'],\n",
        "    #                   range=['lightgray', 'blue', 'red'])),\n",
        "    tooltip=[\"x\", \"y\", \"text\"]\n",
        ").interactive()\n"
      ],
      "metadata": {
        "id": "MQl7EqWBpCAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: BERTopic\n",
        "\n",
        "[BERTopic](https://maartengr.github.io/BERTopic/algorithm/algorithm.html#code-overview) is a more modern approach to topic modeling.\n",
        "\n",
        "Instead of learning of word representations from scratch, typically BERTopic will leverage pre-trained embeddings to provide a deeper knowledge of word meanings.\n",
        "\n",
        "Then, you may use those representations to cluster (e.g., UMAP, DBSCAN, etc.). Typically, this leads to better topics (clusters) but at the cost of more memory/computationally intensive (not too big of a problem unless you have massive data).\n",
        "\n",
        "For these questions, you will likely need to search the [BERTopic](https://maartengr.github.io/BERTopic/index.html) website.\n",
        "\n",
        "Simply saying \"I don't know\" will not be given points; the point of this exercise is to improve your search skills of documentation and make an argument.\n",
        "\n",
        "### What to do:\n",
        "\n",
        "- Run the code below (`.fit_transform()` and then `.get_topic_info()`).\n",
        "\n",
        "- Your boss asked you from this dataset: \"What are most important topics that customers are talking about?\" Answer this question.\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`\n",
        "\n",
        "- Your boss then says: \"There are too many topics; I want fewer topics.\" Describe to your boss what options there are to reduce the number of topics. Rerun (add code) a topic model to accomplish this goal.\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`\n",
        "\n",
        "- Your boss says: \"Hmm... there's a lot of stop words. Should we include them or remove them from the analysis? What are other options we have?\".  Answer this question. You may (although not required to run an example).\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`\n",
        "\n",
        "- Your boss asks about saving the model. Generate code to save the model as a pickle file. As a check, reload your model again.\n",
        "\n",
        "`!<--- CREATE A NEW CODE SNIPPET -->!`\n",
        "\n",
        "- Your boss mentions that the model will be run in a slightly different production environment than Colab. What safeguards can be done to make sure it works and consistent?\n",
        "\n",
        "`!<--- WRITE ANSWER HERE -->!`"
      ],
      "metadata": {
        "id": "-HWtmwwlGeah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step will take 5+ minutes\n",
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic()\n",
        "topics, probs = topic_model.fit_transform(docs)"
      ],
      "metadata": {
        "id": "3H-nHdUNGHN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "cWpsAlsoHAc0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}